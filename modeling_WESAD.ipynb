{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMYBXDrhPG7Qp96pHf/ibcY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kjspring/stress-detection-wearable-devices/blob/main/modeling_WESAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtX5TSM8gfZB",
        "outputId": "36d7c149-9689-4220-fb42-65051a7f7f9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Load pickled data\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os\n",
        "\n",
        "#! cd /content/drive/MyDrive/stress-prediction/ # Main file directory for this notebook on Google Drive\n",
        "os.chdir('/content/drive/MyDrive/stress-prediction')\n",
        "# absolute path of data directory\n",
        "PATH = os.path.join(os.path.abspath(os.getcwd()), 'data') # Path of data folder on Google Drive\n",
        "\n",
        "import joblib\n",
        "data = joblib.load(f\"{PATH}/pickle/WESAD_data_model.pickle\") # read pickle file\n",
        "labels = joblib.load(f\"{PATH}/pickle/WESAD_labels_model.pickle\") # read pickle file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subsample the data and features\n",
        "Hz_chest = 700\n",
        "Hz_EDA = 4\n",
        "subsample_rate = int(Hz_chest / Hz_EDA)  # subsample rate, e.g. to reduce from 700Hz to 4Hz\n",
        "\n",
        "subsampled_data = data[::subsample_rate]\n",
        "subsampled_labels = labels[::subsample_rate]\n",
        "\n",
        "print(len(data))  # 2742499\n",
        "print(len(subsampled_data))  # 15672"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx2IGBv1yaQ7",
        "outputId": "428c95a4-71c9-4ca3-f029-a701b77f51bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2742499\n",
            "15672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for NaN values\n",
        "subsampled_data.isnull().values.any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdxsD6VuL2pJ",
        "outputId": "bdede3b0-c89a-4485-bc89-952903d5a045"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try with a Datagenerator to reduce the RAM use\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "random_state = 42\n",
        "sampling_rate = 5 # keep one data point out of 5\n",
        "duration = 1 # how many minutes in the future the target after the end of the sequence\n",
        "sequence_length = Hz_EDA * 60 * duration # observations will go back duration minutues\n",
        "delay = sampling_rate*(sequence_length + duration*60*Hz_EDA - 1) # the target for a\n",
        "                                                             # sequence will be\n",
        "                                                             # duration (min)\n",
        "                                                             # after the end of\n",
        "                                                             # the sequence\n",
        "batch_size = 64\n",
        "shuffle = True\n",
        "\n",
        "# Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_dat, X_val, y_dat, y_val = train_test_split(subsampled_data, subsampled_labels, \n",
        "                                                 test_size = 0.2,\n",
        "                                                 random_state=random_state)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_dat, y_dat,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = random_state)\n",
        "\n",
        "\n",
        "# Normalize the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# create the StandardScaler object\n",
        "scaler = StandardScaler()\n",
        "# fit the scaler on the training data\n",
        "X_train_scaled = scaler.fit_transform(X_train.values.reshape(-1,1))\n",
        "# transform the validation data\n",
        "X_val_scaled = scaler.transform(X_val.values.reshape(-1,1))\n",
        "# transform the test data\n",
        "X_test_scaled = scaler.transform(X_test.values.reshape(-1,1))\n",
        "\n",
        "# Data Generator\n",
        "train_data_gen = TimeseriesGenerator(X_train_scaled, y_train, length=sequence_length, batch_size=batch_size)\n",
        "val_data_gen = TimeseriesGenerator(X_val_scaled, y_val, length=sequence_length, batch_size=batch_size)\n",
        "test_data_gen = TimeseriesGenerator(X_test_scaled, y_test, length=sequence_length, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "3xkosnn-j7z6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data_gen[0][0].shape) # prints the batch size of the first entry\n",
        "'''\n",
        "A tensor of shape (32, 1200, 1) means that it is a 3-dimensional tensor with 32 \n",
        "rows, 240 columns and 1 channel. In this specific case, it could represent a \n",
        "batch of 32 time series samples, each with 1200 time steps and 1 feature/channel.\n",
        "\n",
        "The first dimension (32) represents the batch size, which is the number of \n",
        "samples that are processed at once during training. The second dimension (1200) \n",
        "represents the time steps or the sequence length of each sample, and the third \n",
        "dimension (1) represents the number of features or channels in each sample.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "JNkaqD_bTfRB",
        "outputId": "f9306188-e838-4fa9-9b1d-5e5239c8c2e2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 240, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nA tensor of shape (32, 1200, 1) means that it is a 3-dimensional tensor with 32 \\nrows, 240 columns and 1 channel. In this specific case, it could represent a \\nbatch of 32 time series samples, each with 1200 time steps and 1 feature/channel.\\n\\nThe first dimension (32) represents the batch size, which is the number of \\nsamples that are processed at once during training. The second dimension (1200) \\nrepresents the time steps or the sequence length of each sample, and the third \\ndimension (1) represents the number of features or channels in each sample.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator = iter(train_data_gen)\n",
        "x_batch, y_batch = next(train_iterator)\n",
        "print(x_batch.shape)\n",
        "print(y_batch.shape)\n",
        "\n",
        "# Validation Data\n",
        "val_iterator = iter(val_data_gen)\n",
        "x_batch, y_batch = next(val_iterator)\n",
        "print(x_batch.shape)\n",
        "print(y_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If_KuXvFhdsN",
        "outputId": "7a5934f2-9e82-4308-9567-df5b013558f9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 240, 1)\n",
            "(64,)\n",
            "(64, 240, 1)\n",
            "(64,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Model\n",
        "def evaluate_naive_method(dataset):\n",
        "  '''\n",
        "  This method uses a common-sense approach to predict that the subject will be\n",
        "  in the same state 5 minutes from now as they are in now.\n",
        "  '''"
      ],
      "metadata": {
        "id": "ft6yb8UANWLq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "#model.add(Dense(batch_size, activation='relu', input_shape=(sequence_length, 1)))\n",
        "model.add(LSTM(64, \n",
        "               activation='relu', \n",
        "               #stateful = True, # To save RAM use,\n",
        "               batch_input_shape=(batch_size, sequence_length, 1))) # Broke after adding Dense\n",
        "               #unroll=True, # unroll the dropout to speed runtime\n",
        "               #recurrent_dropout=0.5)) # Add dropout\n",
        "model.add(Dropout(0.5)) # Dropout\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Callback and Early Stopping\n",
        "#callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
        "#             ModelCheckpoint('models/LSTMmodel_best.keras',\n",
        "#                  save_best_only=True)\n",
        "#]\n",
        "\n",
        "# Compile\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer=Adam(learning_rate=0.00001), \n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "# Train the model using the TimeSeriesGenerator\n",
        "# train the model\n",
        "epochs = 10\n",
        "#total_epochs = 0\n",
        "#for i in range(epochs):\n",
        "#    for j in range(len(train_data_gen)):\n",
        "#      print('Epoch', total_epochs+1, '/', epochs)\n",
        "#      model.fit(train_data_gen, epochs=1, validation_data=val_data_gen, \n",
        "#                verbose=1, shuffle=False, callbacks=callbacks)\n",
        "#      model.reset_states() # Need to reset since using LSTM stateful\n",
        "#      total_epochs += 1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D6BD7Zoheo2",
        "outputId": "c924819d-4f5e-4f67-c717-014590c5a6e2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data_gen, validation_data=val_data_gen,\n",
        "          shuffle=False)#, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lnVpLFhfQbQ9",
        "outputId": "db61c0ad-7180-4aac-bead-b68b5bb80cc4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "152/153 [============================>.] - ETA: 0s - loss: 0.6780 - binary_accuracy: 0.7439"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-86819a2d58fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(train_data_gen, validation_data=val_data_gen,\n\u001b[0m\u001b[1;32m      2\u001b[0m           shuffle=False)#, callbacks=callbacks)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_11/lstm_11/TensorArrayUnstack/TensorListFromTensor' defined at (most recent call last):\n    File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.9/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 821, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-38-86819a2d58fc>\", line 1, in <module>\n      model.fit(train_data_gen, validation_data=val_data_gen,\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/layers/rnn/base_rnn.py\", line 556, in __call__\n      return super().__call__(inputs, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/layers/rnn/lstm.py\", line 625, in call\n      last_output, outputs, states = backend.rnn(\n    File \"/usr/local/lib/python3.9/dist-packages/keras/backend.py\", line 4942, in rnn\n      input_ta = tuple(\n    File \"/usr/local/lib/python3.9/dist-packages/keras/backend.py\", line 4943, in <genexpr>\n      ta.unstack(input_)\nNode: 'sequential_11/lstm_11/TensorArrayUnstack/TensorListFromTensor'\nSpecified a list with shape [64,1] from a tensor with shape [61,1]\n\t [[{{node sequential_11/lstm_11/TensorArrayUnstack/TensorListFromTensor}}]] [Op:__inference_train_function_31154]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation and test dataset\n",
        "\n",
        "score = model.evaluate(val_data_gen)\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])\n",
        "\n",
        "\n",
        "test_loss = model.evaluate(test_data_gen)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "btVwVtufhits"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}