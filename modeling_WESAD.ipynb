{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNmsk/w5hkkESilPkedaK6I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kjspring/stress-detection-wearable-devices/blob/main/modeling_WESAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtX5TSM8gfZB",
        "outputId": "c3f12046-08ea-401b-d5a0-1861b7a2b6aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Load pickled data\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os\n",
        "\n",
        "#! cd /content/drive/MyDrive/stress-prediction/ # Main file directory for this notebook on Google Drive\n",
        "os.chdir('/content/drive/MyDrive/stress-prediction')\n",
        "# absolute path of data directory\n",
        "PATH = os.path.join(os.path.abspath(os.getcwd()), 'data') # Path of data folder on Google Drive\n",
        "\n",
        "import joblib\n",
        "data = joblib.load(f\"{PATH}/pickle/WESAD_data_model.pickle\") # read pickle file\n",
        "labels = joblib.load(f\"{PATH}/pickle/WESAD_labels_model.pickle\") # read pickle file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subsample the data and features\n",
        "subsample_rate = 175  # subsample rate, e.g. to reduce from 700Hz to 4Hz\n",
        "\n",
        "subsampled_data = data[::subsample_rate]\n",
        "subsampled_labels = labels[::subsample_rate]\n",
        "\n",
        "print(len(data))  # 2742499\n",
        "print(len(subsampled_data))  # 15672"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx2IGBv1yaQ7",
        "outputId": "05df9d13-57c2-4962-a8fd-2658fb55c6bc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2742499\n",
            "15672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try with a Datagenerator to reduce the RAM use\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "random_state = 42\n",
        "Hz = 4\n",
        "sampling_rate = 5 # keep one data point out of 5\n",
        "duration = 1 # how many minutes in the future the target after the end of the sequence\n",
        "sequence_length = Hz * 60 * duration # observations will go back duration minutues\n",
        "delay = sampling_rate*(sequence_length + duration*60*Hz - 1) # the target for a\n",
        "                                                             # sequence will be\n",
        "                                                             # duration (min)\n",
        "                                                             # after the end of\n",
        "                                                             # the sequence\n",
        "batch_size = 32\n",
        "shuffle = True\n",
        "\n",
        "# Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_dat, X_val, y_dat, y_val = train_test_split(subsampled_data, subsampled_labels, \n",
        "                                                 test_size = 0.2,\n",
        "                                                 random_state=random_state)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_dat, y_dat,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = random_state)\n",
        "\n",
        "\n",
        "# Normalize the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# create the StandardScaler object\n",
        "scaler = StandardScaler()\n",
        "# fit the scaler on the training data\n",
        "X_train_scaled = scaler.fit_transform(X_train.values.reshape(-1,1))\n",
        "# transform the validation data\n",
        "X_val_scaled = scaler.transform(X_val.values.reshape(-1,1))\n",
        "# transform the test data\n",
        "X_test_scaled = scaler.transform(X_test.values.reshape(-1,1))\n",
        "\n",
        "# Data Generator\n",
        "train_data_gen = TimeseriesGenerator(X_train_scaled, y_train, length=sequence_length, batch_size=batch_size)\n",
        "val_data_gen = TimeseriesGenerator(X_val_scaled, y_val, length=sequence_length, batch_size=batch_size)\n",
        "test_data_gen = TimeseriesGenerator(X_test_scaled, y_test, length=sequence_length, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "3xkosnn-j7z6"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data_gen[0][0].shape[0]) # prints the batch size of the first entry"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNkaqD_bTfRB",
        "outputId": "d5204c03-5fc7-460a-f878-bb06fc393fc0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "#model.add(Dense(batch_size, activation='relu', input_shape=(sequence_length, 1)))\n",
        "model.add(LSTM(64, \n",
        "               activation='relu', \n",
        "               stateful = True, # To save RAM use,\n",
        "               batch_input_shape=(batch_size, sequence_length, 1))) # Broke after adding Dense\n",
        "               #unroll=True, # unroll the dropout to speed runtime\n",
        "               #recurrent_dropout=0.5)) # Add dropout\n",
        "model.add(Dropout(0.5)) # Dropout\n",
        "#model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Callback and Early Stopping\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
        "             ModelCheckpoint('models/LSTMmodel_best.keras',\n",
        "                  save_best_only=True)\n",
        "]\n",
        "\n",
        "# Compile\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer=RMSprop(learning_rate=0.01), \n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "# Train the model using the TimeSeriesGenerator\n",
        "# train the model\n",
        "epochs = 10\n",
        "#total_epochs = 0\n",
        "#for i in range(epochs):\n",
        "#    for j in range(len(train_data_gen)):\n",
        "#      print('Epoch', total_epochs+1, '/', epochs)\n",
        "#      model.fit(train_data_gen, epochs=1, validation_data=val_data_gen, \n",
        "#                verbose=1, shuffle=False, callbacks=callbacks)\n",
        "#      model.reset_states() # Need to reset since using LSTM stateful\n",
        "#      total_epochs += 1\n",
        "\n",
        "model.fit(train_data_gen, validation_data=val_data_gen,\n",
        "          shuffle=False, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9D6BD7Zoheo2",
        "outputId": "51eeaafb-4902-402d-d689-fa6056f86bd1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "305/306 [============================>.] - ETA: 0s - loss: nan - binary_accuracy: 0.8120"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-e011e070555d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#      total_epochs += 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m model.fit(train_data_gen, validation_data=val_data_gen,\n\u001b[0m\u001b[1;32m     43\u001b[0m           shuffle=False, callbacks=callbacks)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_24/lstm_23/TensorArrayUnstack/TensorListFromTensor' defined at (most recent call last):\n    File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.9/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 821, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-62-e011e070555d>\", line 42, in <module>\n      model.fit(train_data_gen, validation_data=val_data_gen,\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/layers/rnn/base_rnn.py\", line 556, in __call__\n      return super().__call__(inputs, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/layers/rnn/lstm.py\", line 625, in call\n      last_output, outputs, states = backend.rnn(\n    File \"/usr/local/lib/python3.9/dist-packages/keras/backend.py\", line 4942, in rnn\n      input_ta = tuple(\n    File \"/usr/local/lib/python3.9/dist-packages/keras/backend.py\", line 4943, in <genexpr>\n      ta.unstack(input_)\nNode: 'sequential_24/lstm_23/TensorArrayUnstack/TensorListFromTensor'\nSpecified a list with shape [32,1] from a tensor with shape [29,1]\n\t [[{{node sequential_24/lstm_23/TensorArrayUnstack/TensorListFromTensor}}]] [Op:__inference_train_function_2070609]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation and test dataset\n",
        "\n",
        "score = model.evaluate(val_data_gen)\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])\n",
        "\n",
        "\n",
        "test_loss = model.evaluate(test_data_gen)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "btVwVtufhits"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}